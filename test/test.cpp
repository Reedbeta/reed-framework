#include <framework.h>
#include <xinput.h>
#include <AntTweakBar.h>
#include <OVR_CAPI_D3D.h>
#include <openvr.h>
#include "shader-slots.h"

// Shader bytecode generated by build process
#include "world_vs.h"
#include "simple_ps.h"
#include "simple_alphatest_ps.h"
#include "shadow_alphatest_ps.h"
#include "tonemap_ps.h"

using namespace util;
using namespace Framework;

// Define error checkers for Oculus APIs
#define CHECK_OVR(f) \
		{ \
			ovrResult result = f; \
			if (OVR_FAILURE(result)) \
			{ \
				ovrErrorInfo errorInfo; \
				ovr_GetLastErrorInfo(&errorInfo); \
				ERR("LibOVR call failed with error code: %d\nFailed call: %s\nError message: %s", result, #f, errorInfo.ErrorString); \
			} \
		}

#define CHECK_OVR_WARN(f) \
		{ \
			ovrResult result = f; \
			if (OVR_FAILURE(result)) \
			{ \
				ovrErrorInfo errorInfo; \
				ovr_GetLastErrorInfo(&errorInfo); \
				WARN("LibOVR call failed with error code: %d\nFailed call: %s\nError message: %s", result, #f, errorInfo.ErrorString); \
			} \
		}

// Define error checkers for OpenVR APIs
#define CHECK_OPENVR_WARN(f) \
		{ \
			vr::VRCompositorError result = f; \
			if (result != vr::VRCompositorError_None) \
			{ \
				char msg[1024]; \
				m_pOpenVRCompositor->GetLastError(msg, dim(msg)); \
				WARN("OpenVR call failed with error code: %d\nFailed call: %s\nError message: %s", result, #f, msg); \
			} \
		}



// Globals

float3 g_vecDirectionalLight = normalize(makefloat3(1.0f, 10.0f, 1.5f));
rgb g_rgbDirectionalLight = makergb(1.1f, 1.0f, 0.7f);
rgb g_rgbSky = makergb(0.37f, 0.52f, 1.0f);

float g_normalOffsetShadow = 1e-5f;		// meters
float g_shadowSharpening = 5.0f;

bool g_useTonemapping = true;
float g_exposure = 1.0f;

bool g_debugKey = false;
float g_debugSlider0 = 0.0f;
float g_debugSlider1 = 0.0f;
float g_debugSlider2 = 0.0f;
float g_debugSlider3 = 0.0f;

const float g_zNear = 0.01f;	// meters
const float g_zFar = 1000.0f;	// meters



// Constant buffers

struct CBFrame								// matches cbuffer CBFrame in shader-common.hlsli
{
	float4x4	m_matWorldToClip;
	float4x4	m_matWorldToUvzwShadow;
	float3x4	m_matWorldToUvzShadowNormal;	// actually float3x3, but constant buffer packing rules...
	point3		m_posCamera;
	float		m_padding0;

	float3		m_vecDirectionalLight;
	float		m_padding1;

	rgb			m_rgbDirectionalLight;
	float		m_padding2;

	float2		m_dimsShadowMap;
	float		m_normalOffsetShadow;
	float		m_shadowSharpening;

	float		m_exposure;					// Exposure multiplier
};

struct CBDebug								// matches cbuffer CBDebug in shader-common.hlsli
{
	float		m_debugKey;					// Mapped to spacebar - 0 if up, 1 if down
	float		m_debugSlider0;				// Mapped to debug sliders in UI
	float		m_debugSlider1;				// ...
	float		m_debugSlider2;				// ...
	float		m_debugSlider3;				// ...
};



// Window class

class TestWindow : public D3D11Window
{
public:
	typedef D3D11Window super;

						TestWindow();

	bool				Init(HINSTANCE hInstance);
	virtual void		Shutdown() override;
	virtual LRESULT		MsgProc(HWND hWnd, UINT message, WPARAM wParam, LPARAM lParam) override;
	virtual void		OnResize(int2_arg dimsNew) override;
	virtual void		OnRender() override;

	void				SetRenderTargetDims(int2_arg dimsNew);
	void				ResetCamera();
	void				DrawMaterials(ID3D11PixelShader * pPs, ID3D11PixelShader * pPsAlphaTest);
	void				RenderScene();
	void				RenderShadowMap();

	// Sponza assets
	Mesh								m_meshSponza;
	MaterialLib							m_mtlLibSponza;
	TextureLib							m_texLibSponza;

	// Render targets
	RenderTarget						m_rtSceneMSAA;
	RenderTarget						m_rtScene;
	DepthStencilTarget					m_dstSceneMSAA;
	ShadowMap							m_shmp;

	// Shaders
	comptr<ID3D11VertexShader>			m_pVsWorld;
	comptr<ID3D11PixelShader>			m_pPsSimple;
	comptr<ID3D11PixelShader>			m_pPsSimpleAlphaTest;
	comptr<ID3D11PixelShader>			m_pPsShadowAlphaTest;
	comptr<ID3D11PixelShader>			m_pPsTonemap;

	// Other stuff
	comptr<ID3D11InputLayout>			m_pInputLayout;
	CB<CBFrame>							m_cbFrame;
	CB<CBDebug>							m_cbDebug;
	Texture2D							m_tex1x1White;
	FPSCamera							m_camera;
	Timer								m_timer;

	// VR headset support
	bool								TryActivateVR();
	void								DeactivateVR();
	bool								IsVRActive() const { return m_oculusSession || m_pOpenVRSystem; }
	float4x4							m_matProjVR[2];

	// Oculus headset support
	bool								TryActivateOculusVR();
	void								DeactivateOculusVR();
	ovrSession							m_oculusSession;
	ovrSwapTextureSet *					m_pOculusSwapTextureSet;
	ovrFovPort							m_eyeFovOculusHMD[2];
	ovrVector3f							m_eyeOffsetsOculusHMD[2];
	ovrPosef							m_poseOculusHMD[2];

	// OpenVR headset support
	bool								TryActivateOpenVR();
	void								DeactivateOpenVR();
	vr::IVRSystem*						m_pOpenVRSystem;
	vr::IVRCompositor*					m_pOpenVRCompositor;
	vr::TrackedDevicePose_t				m_poseOpenVR;
};

// TestWindow implementation

TestWindow::TestWindow()
:	m_oculusSession(nullptr),
	m_pOculusSwapTextureSet(nullptr),
	m_pOpenVRSystem(nullptr),
	m_pOpenVRCompositor(nullptr)
{
	// Disable framework's automatic depth buffer, since we'll create our own
	m_hasDepthBuffer = false;
}

bool TestWindow::Init(HINSTANCE hInstance)
{
	super::Init("TestWindow", "Test", hInstance);

	// Ensure the asset pack is up to date
	static const AssetCompileInfo s_assets[] =
	{
		{ "crytek-sponza/sponza.obj",								ACK_OBJMesh, },
		{ "crytek-sponza/sponza.mtl",								ACK_OBJMtlLib, },
		{ "crytek-sponza/textures/background.tga",					ACK_TextureWithMips, },
		{ "crytek-sponza/textures/backgroundbgr.tga",				ACK_TextureWithMips, },
		{ "crytek-sponza/textures/background_bump.png",				ACK_TextureWithMips, },
		{ "crytek-sponza/textures/chain_texture.tga",				ACK_TextureWithMips, },
		{ "crytek-sponza/textures/chain_texture_bump.png",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/chain_texture_mask.png",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/gi_flag.tga",						ACK_TextureWithMips, },
		{ "crytek-sponza/textures/lion.tga",						ACK_TextureWithMips, },
		{ "crytek-sponza/textures/lion2_bump.png",					ACK_TextureWithMips, },
		{ "crytek-sponza/textures/lion_bump.png",					ACK_TextureWithMips, },
		{ "crytek-sponza/textures/spnza_bricks_a_bump.png",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/spnza_bricks_a_diff.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/spnza_bricks_a_spec.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_arch_bump.png",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_arch_diff.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_arch_spec.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_ceiling_a_diff.tga",		ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_ceiling_a_spec.tga",		ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_column_a_bump.png",		ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_column_a_diff.tga",		ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_column_a_spec.tga",		ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_column_b_bump.png",		ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_column_b_diff.tga",		ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_column_b_spec.tga",		ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_column_c_bump.png",		ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_column_c_diff.tga",		ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_column_c_spec.tga",		ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_curtain_blue_diff.tga",	ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_curtain_diff.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_curtain_green_diff.tga",	ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_details_diff.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_details_spec.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_fabric_blue_diff.tga",		ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_fabric_diff.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_fabric_green_diff.tga",	ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_fabric_spec.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_flagpole_diff.tga",		ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_flagpole_spec.tga",		ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_floor_a_diff.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_floor_a_spec.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_roof_diff.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_thorn_bump.png",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_thorn_diff.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_thorn_mask.png",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/sponza_thorn_spec.tga",			ACK_TextureWithMips, },
		{ "crytek-sponza/textures/vase_bump.png",					ACK_TextureWithMips, },
		{ "crytek-sponza/textures/vase_dif.tga",					ACK_TextureWithMips, },
		{ "crytek-sponza/textures/vase_hanging.tga",				ACK_TextureWithMips, },
		{ "crytek-sponza/textures/vase_plant.tga",					ACK_TextureWithMips, },
		{ "crytek-sponza/textures/vase_plant_mask.png",				ACK_TextureWithMips, },
		{ "crytek-sponza/textures/vase_plant_spec.tga",				ACK_TextureWithMips, },
		{ "crytek-sponza/textures/vase_round.tga",					ACK_TextureWithMips, },
		{ "crytek-sponza/textures/vase_round_bump.png",				ACK_TextureWithMips, },
		{ "crytek-sponza/textures/vase_round_spec.tga",				ACK_TextureWithMips, },
	};
	comptr<AssetPack> pPack = new AssetPack;
	if (!LoadAssetPackOrCompileIfOutOfDate("crytek-sponza-assets.zip", s_assets, dim(s_assets), pPack))
	{
		ERR("Couldn't load or compile Sponza asset pack");
		return false;
	}

	// Load assets
	if (!LoadTextureLibFromAssetPack(pPack, s_assets, dim(s_assets), &m_texLibSponza))
	{
		ERR("Couldn't load Sponza texture library");
		return false;
	}
	if (!LoadMaterialLibFromAssetPack(pPack, "crytek-sponza/sponza.mtl", &m_texLibSponza, &m_mtlLibSponza))
	{
		ERR("Couldn't load Sponza material library");
		return false;
	}
	if (!LoadMeshFromAssetPack(pPack, "crytek-sponza/sponza.obj", &m_mtlLibSponza, &m_meshSponza))
	{
		ERR("Couldn't load Sponza mesh");
		return false;
	}

	// Hardcode a list of alpha-tested materials, for now
	static const char * s_aMtlAlphaTest[] =
	{
		"leaf",
		"material__57",
		"chain",
	};
	for (int i = 0; i < dim(s_aMtlAlphaTest); ++i)
	{
		if (Material * pMtl = m_mtlLibSponza.Lookup(s_aMtlAlphaTest[i]))
			pMtl->m_alphaTest = true;
	}

	// Upload all assets to GPU
	m_meshSponza.UploadToGPU(m_pDevice);
	m_texLibSponza.UploadAllToGPU(m_pDevice);

	// Init shadow map
	m_shmp.Init(m_pDevice, makeint2(4096));

	// Load shaders
	CHECK_D3D(m_pDevice->CreateVertexShader(world_vs_bytecode, dim(world_vs_bytecode), nullptr, &m_pVsWorld));
	CHECK_D3D(m_pDevice->CreatePixelShader(simple_ps_bytecode, dim(simple_ps_bytecode), nullptr, &m_pPsSimple));
	CHECK_D3D(m_pDevice->CreatePixelShader(simple_alphatest_ps_bytecode, dim(simple_alphatest_ps_bytecode), nullptr, &m_pPsSimpleAlphaTest));
	CHECK_D3D(m_pDevice->CreatePixelShader(shadow_alphatest_ps_bytecode, dim(shadow_alphatest_ps_bytecode), nullptr, &m_pPsShadowAlphaTest));
	CHECK_D3D(m_pDevice->CreatePixelShader(tonemap_ps_bytecode, dim(tonemap_ps_bytecode), nullptr, &m_pPsTonemap));

	// Initialize the input layout, and validate it against all the vertex shaders

	D3D11_INPUT_ELEMENT_DESC aInputDescs[] =
	{
		{ "POSITION", 0, DXGI_FORMAT_R32G32B32_FLOAT, 0, UINT(offsetof(Vertex, m_pos)), D3D11_INPUT_PER_VERTEX_DATA, 0 },
		{ "NORMAL", 0, DXGI_FORMAT_R32G32B32_FLOAT, 0, UINT(offsetof(Vertex, m_normal)), D3D11_INPUT_PER_VERTEX_DATA, 0 },
		{ "UV", 0, DXGI_FORMAT_R32G32_FLOAT, 0, UINT(offsetof(Vertex, m_uv)), D3D11_INPUT_PER_VERTEX_DATA, 0 },
	};
	CHECK_D3D(m_pDevice->CreateInputLayout(
							aInputDescs, dim(aInputDescs),
							world_vs_bytecode, dim(world_vs_bytecode),
							&m_pInputLayout));

	// Init constant buffers
	m_cbFrame.Init(m_pDevice);
	m_cbDebug.Init(m_pDevice);

	// Init default textures
	CreateTexture1x1(m_pDevice, makergba(1.0f), &m_tex1x1White);

	// Init the camera
	m_camera.m_moveSpeed = 3.0f;
	m_camera.m_mbuttonActivate = MBUTTON_Left;
	ResetCamera();

	// Init AntTweakBar
	CHECK_ERR(TwInit(TW_DIRECT3D11, m_pDevice));

	// Init libovr
	ovrInitParams ovrParams = {};
	if (OVR_FAILURE(ovr_Initialize(&ovrParams)))
	{
		MessageBox(m_hWnd, "Couldn't init Oculus SDK; HMD support will not be available", "Warning", MB_OK);
	}

	// Automatically use the biggest font size
	TwDefine("GLOBAL fontsize=3 fontresizable=false");

	// Create bar for FPS display
	TwBar * pTwBarFPS = TwNewBar("FPS");
	TwDefine("FPS position='15 15' size='225 80' valueswidth=75 refresh=0.5");
	TwAddVarCB(
			pTwBarFPS, "FPS", TW_TYPE_FLOAT,
			nullptr,
			[](void * value, void * timestep) { 
				*(float *)value = 1.0f / *(float *)timestep;
			},
			&m_timer.m_timestep,
			"precision=1");
	TwAddVarCB(
			pTwBarFPS, "Frame time (ms)", TW_TYPE_FLOAT,
			nullptr,
			[](void * value, void * timestep) { 
				*(float *)value = 1000.0f * *(float *)timestep;
			},
			&m_timer.m_timestep,
			"precision=2");

	// Create bar for debug sliders
	TwBar * pTwBarDebug = TwNewBar("Debug");
	TwDefine("Debug position='15 110' size='225 115' valueswidth=75");
	TwAddVarRW(pTwBarDebug, "g_debugSlider0", TW_TYPE_FLOAT, &g_debugSlider0, "min=0.0 step=0.01 precision=2");
	TwAddVarRW(pTwBarDebug, "g_debugSlider1", TW_TYPE_FLOAT, &g_debugSlider1, "min=0.0 step=0.01 precision=2");
	TwAddVarRW(pTwBarDebug, "g_debugSlider2", TW_TYPE_FLOAT, &g_debugSlider2, "min=0.0 step=0.01 precision=2");
	TwAddVarRW(pTwBarDebug, "g_debugSlider3", TW_TYPE_FLOAT, &g_debugSlider3, "min=0.0 step=0.01 precision=2");

	// Create bar for rendering options
	TwBar * pTwBarRendering = TwNewBar("Rendering");
	TwDefine("Rendering position='15 240' size='275 250' valueswidth=130");
	TwAddVarRW(pTwBarRendering, "Light direction", TW_TYPE_DIR3F, &g_vecDirectionalLight, nullptr);
	TwAddVarRW(pTwBarRendering, "Light color", TW_TYPE_COLOR3F, &g_rgbDirectionalLight, nullptr);
	TwAddVarRW(pTwBarRendering, "Sky color", TW_TYPE_COLOR3F, &g_rgbSky, nullptr);
	TwAddVarRW(pTwBarRendering, "Normal Offset", TW_TYPE_FLOAT, &g_normalOffsetShadow, "min=0.0 max=1e-4 step=1e-6 precision=6 group=Shadow");
	TwAddVarRW(pTwBarRendering, "Sharpening", TW_TYPE_FLOAT, &g_shadowSharpening, "min=0.01 max=10.0 step=0.01 precision=2 group=Shadow");
	TwAddVarRW(pTwBarRendering, "Tonemapping", TW_TYPE_BOOLCPP, &g_useTonemapping, nullptr);
	TwAddVarRW(pTwBarRendering, "Exposure", TW_TYPE_FLOAT, &g_exposure, "min=0.01 max=5.0 step=0.01 precision=2");

	// Create bar for camera position and orientation
	TwBar * pTwBarCamera = TwNewBar("Camera");
	TwDefine("Camera position='255 15' size='195 180' valueswidth=75 refresh=0.5");
	TwAddVarRO(pTwBarCamera, "Camera X", TW_TYPE_FLOAT, &m_camera.m_pos.x, "precision=3");
	TwAddVarRO(pTwBarCamera, "Camera Y", TW_TYPE_FLOAT, &m_camera.m_pos.y, "precision=3");
	TwAddVarRO(pTwBarCamera, "Camera Z", TW_TYPE_FLOAT, &m_camera.m_pos.z, "precision=3");
	TwAddVarRO(pTwBarCamera, "Yaw", TW_TYPE_FLOAT, &m_camera.m_yaw, "precision=3");
	TwAddVarRO(pTwBarCamera, "Pitch", TW_TYPE_FLOAT, &m_camera.m_pitch, "precision=3");
	auto lambdaNegate = [](void * outValue, void * inValue) { *(float *)outValue = -*(float *)inValue; };
	TwAddVarCB(pTwBarCamera, "Look X", TW_TYPE_FLOAT, nullptr, lambdaNegate, &m_camera.m_viewToWorld.m_linear[2].x, "precision=3");
	TwAddVarCB(pTwBarCamera, "Look Y", TW_TYPE_FLOAT, nullptr, lambdaNegate, &m_camera.m_viewToWorld.m_linear[2].y, "precision=3");
	TwAddVarCB(pTwBarCamera, "Look Z", TW_TYPE_FLOAT, nullptr, lambdaNegate, &m_camera.m_viewToWorld.m_linear[2].z, "precision=3");

	// Create bar for VR headset activation
	TwBar * pTwBarVR = TwNewBar("VR Headset");
	TwDefine("'VR Headset' position='15 505' size='225 100'");
	TwAddButton(
		pTwBarVR, "Activate VR",
		[](void * window) {
			((TestWindow *)window)->TryActivateVR();
		}, this, nullptr);
	TwAddButton(
		pTwBarVR, "Deactivate VR",
		[](void * window) {
			((TestWindow *)window)->DeactivateVR();
		}, this, nullptr);

	return true;
}

void TestWindow::Shutdown()
{
	DeactivateVR();
	ovr_Shutdown();

	TwTerminate();

	m_meshSponza.Reset();
	m_mtlLibSponza.Reset();
	m_texLibSponza.Reset();

	m_rtSceneMSAA.Reset();
	m_rtScene.Reset();
	m_dstSceneMSAA.Reset();
	m_shmp.Reset();

	m_pVsWorld.release();
	m_pPsSimple.release();
	m_pPsSimpleAlphaTest.release();
	m_pPsShadowAlphaTest.release();
	m_pPsTonemap.release();

	m_pInputLayout.release();
	m_cbFrame.Reset();
	m_cbDebug.Reset();
	m_tex1x1White.Reset();

	super::Shutdown();
}

LRESULT TestWindow::MsgProc(HWND hWnd, UINT message, WPARAM wParam, LPARAM lParam)
{
	// Give AntTweakBar and the camera a crack at the message
	if (TwEventWin(hWnd, message, wParam, lParam))
		return 0;
	if (m_camera.HandleWindowsMessage(message, wParam, lParam))
		return 0;

	switch (message)
	{
	case WM_KEYDOWN:
		switch (wParam)
		{
		case VK_HOME:
			ResetCamera();
			break;

		case VK_ESCAPE:
			Shutdown();
			break;

		case 'R':
			if (m_oculusSession)
				ovr_RecenterPose(m_oculusSession);
			else if (m_pOpenVRSystem)
				m_pOpenVRSystem->ResetSeatedZeroPose();
			break;
		}
		return 0;

	default:
		return super::MsgProc(hWnd, message, wParam, lParam);
	}
}

void TestWindow::ResetCamera()
{
	m_camera.LookAt(
				makepoint3(-8.7f, 6.8f, 0.0f),
				makepoint3(0.0f, 5.0f, 0.0f));
}

void TestWindow::OnResize(int2_arg dimsNew)
{
	super::OnResize(dimsNew);

	if (!IsVRActive())
	{
		SetRenderTargetDims(dimsNew);
	}

	// Update projection matrix for new aspect ratio
	m_camera.SetProjection(1.0f, float(dimsNew.x) / float(dimsNew.y), g_zNear, g_zFar);
}

void TestWindow::SetRenderTargetDims(int2_arg dimsNew)
{
	if (all(dimsNew == m_rtSceneMSAA.m_dims))
		return;

	// Recreate render targets for the new size
	m_rtSceneMSAA.Reset();
	m_rtScene.Reset();
	m_dstSceneMSAA.Reset();
	m_rtSceneMSAA.Init(m_pDevice, dimsNew, DXGI_FORMAT_R8G8B8A8_UNORM_SRGB, 4);
	m_rtScene.Init(m_pDevice, dimsNew, DXGI_FORMAT_R8G8B8A8_UNORM_SRGB, 1);
	m_dstSceneMSAA.Init(m_pDevice, dimsNew, DXGI_FORMAT_D32_FLOAT, 4);
}

void TestWindow::OnRender()
{
	m_timer.OnFrameStart();
	m_camera.Update(m_timer.m_timestep);

	if (IsVRActive())
	{
		// Force camera pitch to zero, so pitch is only from HMD orientation
		m_camera.m_pitch = 0.0f;
		m_camera.UpdateOrientation();

		// Retrieve head-tracking information from the VR API
		if (m_oculusSession)
		{
			ovr_GetEyePoses(m_oculusSession, m_timer.m_frameCount, true, m_eyeOffsetsOculusHMD, m_poseOculusHMD, nullptr);
		}
		else if (m_pOpenVRSystem)
		{
			CHECK_OPENVR_WARN(m_pOpenVRCompositor->WaitGetPoses(&m_poseOpenVR, 1, nullptr, 0));
		}
	}

	m_pCtx->ClearState();
	m_pCtx->IASetInputLayout(m_pInputLayout);
	m_pCtx->OMSetDepthStencilState(m_pDssDepthTest, 0);

	// Set up debug parameters constant buffer

	XINPUT_STATE controllerState = {};
	{
		static bool controllerPresent = true;
		if (controllerPresent && XInputGetState(0, &controllerState) != ERROR_SUCCESS)
			controllerPresent = false;
	}
	// !!!UNDONE: move keyboard tracking into an input system that respects focus, etc.
	g_debugKey = (GetAsyncKeyState(' ') || (controllerState.Gamepad.wButtons & XINPUT_GAMEPAD_A));

	CBDebug cbDebug =
	{
		// !!!UNDONE: move keyboard tracking into an input system that respects focus, etc.
		g_debugKey ? 1.0f : 0.0f,
		g_debugSlider0,
		g_debugSlider1,
		g_debugSlider2,
		g_debugSlider3,
	};
	m_cbDebug.Update(m_pCtx, &cbDebug);
	m_cbDebug.Bind(m_pCtx, CB_DEBUG);

	RenderShadowMap();
	RenderScene();

	bool vrDisplayLost = false;
	if (m_oculusSession)
	{
		// Blit the frame to the Oculus swap texture set (would have rendered directly to it,
		// but then it seems you can't blit from it to the back buffer - we just get black).
		ovrD3D11Texture * pOVRTex = (ovrD3D11Texture *)&m_pOculusSwapTextureSet->Textures[m_pOculusSwapTextureSet->CurrentIndex];
		ASSERT_WARN(all(makeint2(&pOVRTex->Texture.Header.TextureSize.w) == m_rtScene.m_dims));
		m_pCtx->CopySubresourceRegion(pOVRTex->D3D11.pTexture, 0, 0, 0, 0, m_rtScene.m_pTex, 0, nullptr);

		// Submit the frame to the Oculus runtime
		ovrLayerEyeFov layerMain = {};
		layerMain.Header.Type = ovrLayerType_EyeFov;
		layerMain.Header.Flags = ovrLayerFlag_HighQuality;
		layerMain.ColorTexture[0] = m_pOculusSwapTextureSet;
		layerMain.Viewport[ovrEye_Left].Size.w = m_rtSceneMSAA.m_dims.x / 2;
		layerMain.Viewport[ovrEye_Left].Size.h = m_rtSceneMSAA.m_dims.y;
		layerMain.Viewport[ovrEye_Right].Pos.x = m_rtSceneMSAA.m_dims.x / 2;
		layerMain.Viewport[ovrEye_Right].Size.w = m_rtSceneMSAA.m_dims.x / 2;
		layerMain.Viewport[ovrEye_Right].Size.h = m_rtSceneMSAA.m_dims.y;
		layerMain.Fov[ovrEye_Left] = m_eyeFovOculusHMD[ovrEye_Left];
		layerMain.Fov[ovrEye_Right] = m_eyeFovOculusHMD[ovrEye_Right];
		layerMain.RenderPose[ovrEye_Left] = m_poseOculusHMD[ovrEye_Left];
		layerMain.RenderPose[ovrEye_Right] = m_poseOculusHMD[ovrEye_Right];
		ovrLayerHeader * layerList[] = { &layerMain.Header };
		ovrResult result = ovr_SubmitFrame(m_oculusSession, m_timer.m_frameCount, nullptr, layerList, dim(layerList));
		if (result == ovrError_DisplayLost)
		{
			// Display was powered off, or something. Set flag to turn off VR mode next frame.
			vrDisplayLost = true;
		}
		else if (OVR_FAILURE(result))
		{
			ovrErrorInfo errorInfo;
			ovr_GetLastErrorInfo(&errorInfo);
			WARN("ovr_SubmitFrame failed with error code: %d\nError message: %s", result, errorInfo.ErrorString);
		}

		// Cycle through textures in the set
		m_pOculusSwapTextureSet->CurrentIndex = (m_pOculusSwapTextureSet->CurrentIndex + 1) % m_pOculusSwapTextureSet->TextureCount;
	}
	else if (m_pOpenVRSystem)
	{
		// Submit the frame to the OpenVR runtime
		vr::VRTextureBounds_t bounds = { 0.0f, 0.0f, 0.5f, 1.0f };
		CHECK_OPENVR_WARN(m_pOpenVRCompositor->Submit(vr::Hmd_Eye::Eye_Left, vr::API_DirectX, m_rtScene.m_pTex, &bounds));
		bounds = { 0.5f, 0.0f, 1.0f, 1.0f };
		CHECK_OPENVR_WARN(m_pOpenVRCompositor->Submit(vr::Hmd_Eye::Eye_Right, vr::API_DirectX, m_rtScene.m_pTex, &bounds));
	}

	// Blit the frame to the window - straight copy if same dims, bilinear resize otherwise
	if (all(m_rtScene.m_dims == m_dims))
	{
		m_pCtx->CopySubresourceRegion(m_pTexBackBuffer, 0, 0, 0, 0, m_rtScene.m_pTex, 0, nullptr);
	}
	else
	{
		BindSRGBBackBuffer(m_pCtx);
		m_pCtx->OMSetDepthStencilState(m_pDssNoDepthTest, 0);
		BlitFullscreen(m_pCtx, m_rtScene.m_pSrv);
	}

	// Draw AntTweakBar UI on window (not on VR headset)
	BindRawBackBuffer(m_pCtx);
	CHECK_WARN(TwDraw());

	// Present to window - no vsync in VR mode; assume the VR API will take care of that
	CHECK_D3D(m_pSwapChain->Present(IsVRActive() ? 0 : 1, 0));

	// Turn off VR mode if we lost the headset. This is deferred to end of frame
	// because it can resize render targets and things like that.
	if (vrDisplayLost)
		DeactivateVR();
}

void TestWindow::DrawMaterials(ID3D11PixelShader * pPs, ID3D11PixelShader * pPsAlphaTest)
{
	// Draw the individual material ranges of the mesh

	// Non-alpha-tested materials
	m_pCtx->PSSetShader(pPs, nullptr, 0);
	m_pCtx->RSSetState(m_pRsDefault);
	for (int i = 0, c = int(m_meshSponza.m_mtlRanges.size()); i < c; ++i)
	{
		Material * pMtl = m_meshSponza.m_mtlRanges[i].m_pMtl;
		ASSERT_ERR(pMtl);

		if (pMtl->m_alphaTest)
			continue;

		if (pPs)
		{
			ID3D11ShaderResourceView * pSrv = m_tex1x1White.m_pSrv;
			if (Texture2D * pTex = pMtl->m_pTexDiffuseColor)
				pSrv = pTex->m_pSrv;
			m_pCtx->PSSetShaderResources(TEX_DIFFUSE, 1, &pSrv);
		}

		m_meshSponza.DrawMtlRange(m_pCtx, i);
	}

	// Alpha-tested materials
	m_pCtx->PSSetShader(pPsAlphaTest, nullptr, 0);
	m_pCtx->RSSetState(m_pRsDoubleSided);
	for (int i = 0, c = int(m_meshSponza.m_mtlRanges.size()); i < c; ++i)
	{
		Material * pMtl = m_meshSponza.m_mtlRanges[i].m_pMtl;
		ASSERT_ERR(pMtl);

		if (!pMtl->m_alphaTest)
			continue;

		if (pPsAlphaTest)
		{
			ID3D11ShaderResourceView * pSrv = m_tex1x1White.m_pSrv;
			if (Texture2D * pTex = pMtl->m_pTexDiffuseColor)
				pSrv = pTex->m_pSrv;
			m_pCtx->PSSetShaderResources(TEX_DIFFUSE, 1, &pSrv);
		}

		m_meshSponza.DrawMtlRange(m_pCtx, i);
	}
}

void TestWindow::RenderScene()
{
	// Crytek Sponza is authored in centimeters; convert to meters
	float sceneScale = 0.01f;
	float4x4 matSceneScale = diagonal(makefloat4(sceneScale, sceneScale, sceneScale, 1.0f));

	// Set up constant buffer for rendering to shadow map
	CBFrame cbFrame =
	{
		{},	// m_matWorldToClip - filled in later
		matSceneScale * m_shmp.m_matWorldToUvzw,
		makefloat3x4(m_shmp.m_matWorldToUvzNormal),
		{},	// m_posCamera - filled in later
		0,	// padding
		g_vecDirectionalLight,
		0,	// padding
		g_rgbDirectionalLight,
		0,	// padding
		makefloat2(m_shmp.m_dst.m_dims),
		g_normalOffsetShadow,
		g_shadowSharpening,
		g_exposure,
	};
	m_cbFrame.Bind(m_pCtx, CB_FRAME);

	m_pCtx->ClearRenderTargetView(m_rtSceneMSAA.m_pRtv, makergba(toLinear(g_rgbSky), 1.0f));
	m_pCtx->ClearDepthStencilView(m_dstSceneMSAA.m_pDsv, D3D11_CLEAR_DEPTH, 1.0f, 0);
	BindRenderTargets(m_pCtx, &m_rtSceneMSAA, &m_dstSceneMSAA);

	m_pCtx->VSSetShader(m_pVsWorld, nullptr, 0);

	m_pCtx->PSSetShaderResources(TEX_SHADOW, 1, &m_shmp.m_dst.m_pSrvDepth);
	m_pCtx->PSSetSamplers(SAMP_DEFAULT, 1, &m_pSsTrilinearRepeatAniso);
	m_pCtx->PSSetSamplers(SAMP_SHADOW, 1, &m_pSsPCF);

	if (!IsVRActive())
	{
		// Render mono for non-VR mode

		cbFrame.m_matWorldToClip = matSceneScale * m_camera.m_worldToClip;
		cbFrame.m_posCamera = m_camera.m_pos;
		m_cbFrame.Update(m_pCtx, &cbFrame);

		DrawMaterials(m_pPsSimple, m_pPsSimpleAlphaTest);
	}
	else
	{
		// Render stereo for VR mode
		for (int eye = 0; eye < 2; ++eye)
		{
			// Figure out the camera pose for this eye, from the VR tracking system
			affine3 eyeToCamera = affine3::identity();
			if (m_oculusSession)
			{
				ovrPosef hmdPose = m_poseOculusHMD[eye];
				quat hmdOrientation =
				{
					hmdPose.Orientation.w,		// Note, different layout from Oculus quaternion!
					hmdPose.Orientation.x,
					hmdPose.Orientation.y,
					hmdPose.Orientation.z
				};
				eyeToCamera = makeaffine3(hmdOrientation, makefloat3(&hmdPose.Position.x));
			}
			else if (m_pOpenVRSystem)
			{
				vr::HmdMatrix34_t eyeToHeadOpenVR = m_pOpenVRSystem->GetEyeToHeadTransform(vr::Hmd_Eye(eye));
				affine3 eyeToHMD =
				{	// transposed from column-vector to row-vector convention
					eyeToHeadOpenVR.m[0][0], eyeToHeadOpenVR.m[1][0], eyeToHeadOpenVR.m[2][0],
					eyeToHeadOpenVR.m[0][1], eyeToHeadOpenVR.m[1][1], eyeToHeadOpenVR.m[2][1],
					eyeToHeadOpenVR.m[0][2], eyeToHeadOpenVR.m[1][2], eyeToHeadOpenVR.m[2][2],
					eyeToHeadOpenVR.m[0][3], eyeToHeadOpenVR.m[1][3], eyeToHeadOpenVR.m[2][3],
				};

				vr::HmdMatrix34_t hmdPose = m_poseOpenVR.mDeviceToAbsoluteTracking;
				affine3 hmdToCamera =
				{	// transposed from column-vector to row-vector convention
					hmdPose.m[0][0], hmdPose.m[1][0], hmdPose.m[2][0],
					hmdPose.m[0][1], hmdPose.m[1][1], hmdPose.m[2][1],
					hmdPose.m[0][2], hmdPose.m[1][2], hmdPose.m[2][2],
					hmdPose.m[0][3], hmdPose.m[1][3], hmdPose.m[2][3],
				};

				eyeToCamera = eyeToHMD * hmdToCamera;
			}

			// Calculate world-to-clip matrix for this eye
			affine3 eyeToWorld = eyeToCamera * m_camera.m_viewToWorld;
			affine3 worldToEye = transpose(eyeToWorld);
			float4x4 worldToClip = matSceneScale * affineToHomogeneous(worldToEye) * m_matProjVR[eye];

			// Update constant buffer data for the new matrices
			cbFrame.m_matWorldToClip = worldToClip;
			cbFrame.m_posCamera = makepoint3(eyeToWorld.m_translation);
			m_cbFrame.Update(m_pCtx, &cbFrame);

			// Set viewport to half of the render target
			SetViewport(m_pCtx, makebox2(float(m_rtSceneMSAA.m_dims.x / 2 * eye), 0.0f, float(m_rtSceneMSAA.m_dims.x / 2 * (eye + 1)), float(m_rtSceneMSAA.m_dims.y)));

			DrawMaterials(m_pPsSimple, m_pPsSimpleAlphaTest);
		}
	}

	// Resolve from the MSAA buffer to the back buffer (or in VR mode, the buffer that will be submitted to the API)
	if (g_useTonemapping)
	{
		// Custom resolve + tonemapping pass
		m_rtScene.Bind(m_pCtx);
		m_pCtx->OMSetDepthStencilState(m_pDssNoDepthTest, 0);
		m_pCtx->PSSetShader(m_pPsTonemap, nullptr, 0);
		m_pCtx->PSSetShaderResources(0, 1, &m_rtSceneMSAA.m_pSrv);
		DrawFullscreenPass(m_pCtx);
	}
	else
	{
		// Standard box filter resolve
		m_pCtx->ResolveSubresource(m_rtScene.m_pTex, 0, m_rtSceneMSAA.m_pTex, 0, DXGI_FORMAT_R8G8B8A8_UNORM_SRGB);
	}
}

void TestWindow::RenderShadowMap()
{
	// Crytek Sponza is authored in centimeters; convert to meters
	float sceneScale = 0.01f;
	float4x4 matSceneScale = diagonal(makefloat4(sceneScale, sceneScale, sceneScale, 1.0f));

	// Calculate shadow map matrices
	m_shmp.m_vecLight = g_vecDirectionalLight;
	m_shmp.m_boundsScene = makebox3(m_meshSponza.m_bounds.m_mins * sceneScale, m_meshSponza.m_bounds.m_maxs * sceneScale);
	m_shmp.UpdateMatrix();

	m_pCtx->IASetInputLayout(m_pInputLayout);
	m_pCtx->OMSetDepthStencilState(m_pDssDepthTest, 0);

	// Set up constant buffer for rendering to shadow map
	CBFrame cbFrame =
	{
		matSceneScale * m_shmp.m_matWorldToClip,
	};
	m_cbFrame.Update(m_pCtx, &cbFrame);
	m_cbFrame.Bind(m_pCtx, CB_FRAME);

	m_pCtx->ClearDepthStencilView(m_shmp.m_dst.m_pDsv, D3D11_CLEAR_DEPTH, 1.0f, 0);
	m_shmp.Bind(m_pCtx);

	m_pCtx->VSSetShader(m_pVsWorld, nullptr, 0);
	m_pCtx->PSSetSamplers(SAMP_DEFAULT, 1, &m_pSsTrilinearRepeatAniso);

	DrawMaterials(nullptr, m_pPsShadowAlphaTest);
}

bool TestWindow::TryActivateVR()
{
	if (IsVRActive())
		return true;

	// Detect Oculus headset
	ovrHmdDesc oculusHmdDesc = ovr_GetHmdDesc(nullptr);
	if (oculusHmdDesc.Type != ovrHmd_None)
	{
		if (TryActivateOculusVR())
		{
			return true;
		}
		else
		{
			DeactivateOculusVR();
			return false;
		}
	}

	// Detect OpenVR headset
	if (vr::VR_IsHmdPresent())
	{
		if (TryActivateOpenVR())
		{
			return true;
		}
		else
		{
			DeactivateOpenVR();
			return false;
		}
	}

	ERR("No VR headset detected");
	return false;
}

void TestWindow::DeactivateVR()
{
	if (m_oculusSession)
		DeactivateOculusVR();
	else if (m_pOpenVRSystem)
		DeactivateOpenVR();

	// Reset render target size to match window size
	SetRenderTargetDims(m_dims);
}

bool TestWindow::TryActivateOculusVR()
{
	// Connect to HMD
	ovrGraphicsLuid oculusLuid = {};
	if (OVR_FAILURE(ovr_Create(&m_oculusSession, &oculusLuid)))
		return false;
	ASSERT_ERR(m_oculusSession);
	if (!m_oculusSession)
		return false;

	// Check that the adapter LUID matches our DX11 device
	comptr<IDXGIDevice> pDXGIDevice;
	CHECK_D3D(m_pDevice->QueryInterface<IDXGIDevice>(&pDXGIDevice));
	comptr<IDXGIAdapter> pAdapter;
	CHECK_D3D(pDXGIDevice->GetAdapter(&pAdapter));
	DXGI_ADAPTER_DESC adapterDesc;
	CHECK_D3D(pAdapter->GetDesc(&adapterDesc));
	cassert(sizeof(adapterDesc.AdapterLuid) == sizeof(oculusLuid));
	if (memcmp(&adapterDesc.AdapterLuid, &oculusLuid, sizeof(oculusLuid)) != 0)
	{
		ERR("Oculus VR headset is connected to a different GPU than the app is running on.");
		return false;
	}

	// Create swap texture set for both eyes side-by-side
	ovrHmdDesc hmdDesc = ovr_GetHmdDesc(m_oculusSession);
	ovrSizei eyeSizeLeft = ovr_GetFovTextureSize(m_oculusSession, ovrEye_Left, hmdDesc.DefaultEyeFov[0], 1.0f);
	ovrSizei eyeSizeRight = ovr_GetFovTextureSize(m_oculusSession, ovrEye_Right, hmdDesc.DefaultEyeFov[1], 1.0f);
	int2 dimsRenderTarget = { max(eyeSizeLeft.w, eyeSizeRight.w) * 2, max(eyeSizeLeft.h, eyeSizeRight.h) };
	D3D11_TEXTURE2D_DESC texDesc =
	{
		UINT(dimsRenderTarget.x), UINT(dimsRenderTarget.y), 1, 1,
		DXGI_FORMAT_R8G8B8A8_UNORM_SRGB,
		{ 1, 0 },
		D3D11_USAGE_DEFAULT,
		D3D11_BIND_RENDER_TARGET | D3D11_BIND_SHADER_RESOURCE,
	};
	CHECK_OVR(ovr_CreateSwapTextureSetD3D11(
					m_oculusSession,
					m_pDevice,
					&texDesc,
					ovrSwapTextureSetD3D11_Typeless,
					&m_pOculusSwapTextureSet));
	ASSERT_ERR(m_pOculusSwapTextureSet);
	if (!m_pOculusSwapTextureSet)
		return false;

	// Set new render target size for side-by-side stereo
	SetRenderTargetDims(dimsRenderTarget);

	// Set new projection matrices
	for (int i = 0; i < 2; ++i)
	{
		m_matProjVR[i] = perspProjD3DStyle(
							-hmdDesc.DefaultEyeFov[i].LeftTan * g_zNear,
							hmdDesc.DefaultEyeFov[i].RightTan * g_zNear,
							-hmdDesc.DefaultEyeFov[i].DownTan * g_zNear,
							hmdDesc.DefaultEyeFov[i].UpTan * g_zNear,
							g_zNear,
							g_zFar);

		// Store the eye FOVs and offset vectors for later use
		m_eyeFovOculusHMD[i] = hmdDesc.DefaultEyeFov[i];
		ovrEyeRenderDesc eyeRenderDesc = ovr_GetRenderDesc(m_oculusSession, ovrEyeType(i), hmdDesc.DefaultEyeFov[i]);
		m_eyeOffsetsOculusHMD[i] = eyeRenderDesc.HmdToEyeViewOffset;
	}

	return true;
}

void TestWindow::DeactivateOculusVR()
{
	if (m_pOculusSwapTextureSet)
	{
		ovr_DestroySwapTextureSet(m_oculusSession, m_pOculusSwapTextureSet);
		m_pOculusSwapTextureSet = nullptr;
	}

	if (m_oculusSession)
	{
		ovr_Destroy(m_oculusSession);
		m_oculusSession = nullptr;
	}
}

bool TestWindow::TryActivateOpenVR()
{
	// Loading the SteamVR Runtime
	vr::HmdError hmdError;
	m_pOpenVRSystem = vr::VR_Init(&hmdError);
	if (hmdError != vr::HmdError_None)
	{
		ERR("VR_Init failed with error code: %d\nError message: %s", hmdError, vr::VR_GetStringForHmdError(hmdError));
		return false;
	}

	// Init compositor.
	m_pOpenVRCompositor = (vr::IVRCompositor *)vr::VR_GetGenericInterface(vr::IVRCompositor_Version, &hmdError);
	if (hmdError != vr::HmdError_None)
	{
		ERR("VR_GetGenericInterface failed with error code: %d\nError message: %s", hmdError, vr::VR_GetStringForHmdError(hmdError));
		return false;
	}

	// Set new render target size for side-by-side stereo
	uint32_t eyeWidth, eyeHeight;
	m_pOpenVRSystem->GetRecommendedRenderTargetSize(&eyeWidth, &eyeHeight);
	SetRenderTargetDims(makeint2(eyeWidth * 2, eyeHeight));

	// Set new projection matrices
	for (int i = 0; i < 2; ++i)
	{
		vr::HmdMatrix44_t matProj = m_pOpenVRSystem->GetProjectionMatrix(vr::Hmd_Eye(i), g_zNear, g_zFar, vr::API_DirectX);
		m_matProjVR[i] = transpose(makefloat4x4(&matProj.m[0][0]));
	}

	return true;
}

void TestWindow::DeactivateOpenVR()
{
	if (m_pOpenVRSystem)
	{
		vr::VR_Shutdown();
		m_pOpenVRSystem = nullptr;
		m_pOpenVRCompositor = nullptr;
	}
}



// Get the whole shebang going

int WINAPI WinMain(HINSTANCE hInstance, HINSTANCE hPrevInstance, LPSTR lpCmdLine, int nCmdShow)
{
	(void)hPrevInstance;
	(void)lpCmdLine;
	(void)nCmdShow;

	TestWindow w;
	if (!w.Init(hInstance))
	{
		w.Shutdown();
		return 1;
	}

	w.MainLoop(SW_SHOWMAXIMIZED);
	return 0;
}
