#include <framework.h>
#include <AntTweakBar.h>
#include "shader-common.h"

#define OVR_D3D_VERSION 11
#include <OVR.h>
#include <OVR_CAPI_D3D.h>

// Shader bytecode generated by build process
#include "world_vs.h"
#include "simple_ps.h"

#pragma warning(disable: 4351)	// "new behavior: elements of array will be default initialized"

using namespace util;
using namespace Framework;



// Globals

float3 g_vecDirectionalLight = normalize(makefloat3(1, 1, 1));
rgb g_rgbDirectionalLight = makergb(1.0f, 1.0f, 0.77f);
srgb g_srgbSky = makergb(0.44f, 0.56f, 1.0f);

float g_debugSlider0 = 0.0f;
float g_debugSlider1 = 0.0f;
float g_debugSlider2 = 0.0f;
float g_debugSlider3 = 0.0f;



// Constant buffers

struct CBFrame								// matches cbuffer CBFrame in shader-common.h
{
	float4x4	m_matWorldToClip;
	float4x4	m_matWorldToUvzwShadow;
	point3		m_posCamera;
	float		m_dummy0;

	float3		m_vecDirectionalLight;
	float		m_dummy1;

	rgb			m_rgbDirectionalLight;
	float		m_exposure;					// Exposure multiplier
};

struct CBDebug								// matches cbuffer CBDebug in shader-common.h
{
	float		m_debugKey;					// Mapped to spacebar - 0 if up, 1 if down
	float		m_debugSlider0;				// Mapped to debug sliders in UI
	float		m_debugSlider1;				// ...
	float		m_debugSlider2;				// ...
	float		m_debugSlider3;				// ...
};



// Window class

class TestWindow : public D3D11Window
{
public:
	typedef D3D11Window super;

						TestWindow();

	bool				Init(HINSTANCE hInstance);
	virtual void		Shutdown();
	virtual LRESULT		MsgProc(HWND hWnd, UINT message, WPARAM wParam, LPARAM lParam);
	virtual void		OnResize(int2_arg dimsNew);
	virtual void		OnRender();

	ovrHmd								m_hmd;
	RenderTarget						m_rtEyes;
	DepthStencilTarget					m_dstEyes;
	comptr<ID3D11ShaderResourceView>	m_pSrvEyesRaw;
	float3								m_eyeOffsets[2];
	float4x4							m_eyeProjections[2];
	ibox2								m_eyeViewports[2];
	ovrD3D11Texture						m_ovrEyeTextures[2];

	Mesh								m_meshSponza;
	Texture2D							m_texStone;
	comptr<ID3D11VertexShader>			m_pVsWorld;
	comptr<ID3D11PixelShader>			m_pPsSimple;
	comptr<ID3D11InputLayout>			m_pInputLayout;
	CB<CBFrame>							m_cbFrame;
	CB<CBDebug>							m_cbDebug;
	FPSCamera							m_camera;
	Timer								m_timer;
};

// TestWindow implementation

TestWindow::TestWindow()
: super(),
  m_hmd(nullptr),
  m_rtEyes(),
  m_dstEyes(),
  m_pSrvEyesRaw(),
  m_eyeOffsets(),
  m_eyeProjections(),
  m_eyeViewports(),
  m_ovrEyeTextures(),
  m_meshSponza(),
  m_texStone(),
  m_pVsWorld(),
  m_pPsSimple(),
  m_pInputLayout(),
  m_cbFrame(),
  m_cbDebug(),
  m_camera(),
  m_timer()
{
}

bool TestWindow::Init(HINSTANCE hInstance)
{
	// Init libovr
	if (!ovr_Initialize())
	{
		ERR("Couldn't init Oculus SDK");
		return false;
	}
	m_hmd = ovrHmd_Create(0);
	if (!m_hmd)
	{
		// If no HMD connected, just fake a DK2 so the app can still run
		m_hmd = ovrHmd_CreateDebug(ovrHmd_DK2);
		ASSERT_ERR(m_hmd);
	}

	// Init OVR head-tracking
	CHECK_ERR(ovrHmd_ConfigureTracking(
				m_hmd,
				ovrTrackingCap_Orientation | ovrTrackingCap_MagYawCorrection | ovrTrackingCap_Position,
				0));

	// Init D3D
	super::Init("TestWindow", "Test", hInstance);

	// Resize swap chain to the size of the HMD (note, swap chain size does not match window size)
	// Don't create depth buffer, as we're going to do that with our offscreen RT
	m_hasDepthBuffer = false;
	super::OnResize(makeint2(m_hmd->Resolution.w, m_hmd->Resolution.h));

	// Hook up OVR to the swap chain
	ovrD3D11Config oculusConfig = {};
	oculusConfig.D3D11.Header.API = ovrRenderAPI_D3D11;
	oculusConfig.D3D11.Header.RTSize.w = m_dims.x;
	oculusConfig.D3D11.Header.RTSize.h = m_dims.y;
	oculusConfig.D3D11.Header.Multisample = 1;
	oculusConfig.D3D11.pDevice = m_pDevice;
	oculusConfig.D3D11.pDeviceContext = m_pCtx;
	oculusConfig.D3D11.pBackBufferRT = m_pRtvRaw;
	oculusConfig.D3D11.pSwapChain = m_pSwapChain;
	ovrEyeRenderDesc oculusEyeDescs[2];
	CHECK_ERR(ovrHmd_ConfigureRendering(
				m_hmd,
				&oculusConfig.Config,
				ovrDistortionCap_Chromatic | ovrDistortionCap_TimeWarp | ovrDistortionCap_SRGB | ovrDistortionCap_Overdrive,
				m_hmd->DefaultEyeFov,
				oculusEyeDescs));
	CHECK_ERR(ovrHmd_AttachToWindow(m_hmd, m_hWnd, nullptr, nullptr));

	// Calculate size for internal eye render target
	ovrSizei leftEyeSize = ovrHmd_GetFovTextureSize(m_hmd, ovrEye_Left, m_hmd->DefaultEyeFov[0], 1.0f);
	ovrSizei rightEyeSize = ovrHmd_GetFovTextureSize(m_hmd, ovrEye_Right, m_hmd->DefaultEyeFov[1], 1.0f);
	int2 eyeDims = { leftEyeSize.w + rightEyeSize.w, max(leftEyeSize.h, rightEyeSize.h) };
	// Round off dims to the next highest 32, just for sanity's sake
	eyeDims = makeint2(roundUp(eyeDims.x, 32), roundUp(eyeDims.y, 32));

	// Create the render target
	m_rtEyes.Init(m_pDevice, eyeDims, DXGI_FORMAT_R8G8B8A8_UNORM_SRGB);
	m_dstEyes.Init(m_pDevice, eyeDims, DXGI_FORMAT_D32_FLOAT);

	// Create a raw-format (not SRGB) view of the render target
	D3D11_SHADER_RESOURCE_VIEW_DESC srvDesc =
	{
		DXGI_FORMAT_R8G8B8A8_UNORM,
		D3D11_SRV_DIMENSION_TEXTURE2D,
	};
	srvDesc.Texture2D.MipLevels = 1;
	CHECK_D3D(m_pDevice->CreateShaderResourceView(m_rtEyes.m_pTex, &srvDesc, &m_pSrvEyesRaw));

	// Calculate per-eye offset vectors, projection matrices, and viewports,
	// and setup OVR texture structs
	float zNear = 0.01f;
	float zFar = 1000.0f;
	for (int i = 0; i < 2; ++i)
	{
		// Negate the offset vector from the SDK, since it's given to us reversed
		m_eyeOffsets[i] = -makefloat3(oculusEyeDescs[i].ViewAdjust.x, oculusEyeDescs[i].ViewAdjust.y, oculusEyeDescs[i].ViewAdjust.z);

		m_eyeProjections[i] = perspProjD3DStyle(
									-oculusEyeDescs[i].Fov.LeftTan * zNear,
									oculusEyeDescs[i].Fov.RightTan * zNear,
									-oculusEyeDescs[i].Fov.DownTan * zNear,
									oculusEyeDescs[i].Fov.UpTan * zNear,
									zNear,
									zFar);

		m_eyeViewports[i] = makeibox2(eyeDims.x / 2 * i, 0, eyeDims.x / 2 * (i + 1), eyeDims.y);

		m_ovrEyeTextures[i].D3D11.Header.API = ovrRenderAPI_D3D11;
		m_ovrEyeTextures[i].D3D11.Header.TextureSize.w = m_rtEyes.m_dims.x;
		m_ovrEyeTextures[i].D3D11.Header.TextureSize.h = m_rtEyes.m_dims.y;
		m_ovrEyeTextures[i].D3D11.Header.RenderViewport.Pos.x = m_eyeViewports[i].m_mins.x;
		m_ovrEyeTextures[i].D3D11.Header.RenderViewport.Pos.y = m_eyeViewports[i].m_mins.y;
		m_ovrEyeTextures[i].D3D11.Header.RenderViewport.Size.w = m_eyeViewports[i].diagonal().x;
		m_ovrEyeTextures[i].D3D11.Header.RenderViewport.Size.h = m_eyeViewports[i].diagonal().y;
		m_ovrEyeTextures[i].D3D11.pTexture = m_rtEyes.m_pTex;
		m_ovrEyeTextures[i].D3D11.pSRView = m_pSrvEyesRaw;
	}
	
	// Load assets
	if (!LoadObjMesh(m_pDevice, "..\\sponza\\sponza_cracksFilled.obj", &m_meshSponza))
	{
		ERR("Couldn't load Sponza mesh");
		return false;
	}
	if (!LoadTexture2D(m_pDevice, "..\\sponza\\kamen.jpg", &m_texStone))
	{
		ERR("Couldn't load Sponza stone texture");
		return false;
	}

	// Load shaders
	CHECK_D3D(m_pDevice->CreateVertexShader(world_vs_bytecode, dim(world_vs_bytecode), nullptr, &m_pVsWorld));
	CHECK_D3D(m_pDevice->CreatePixelShader(simple_ps_bytecode, dim(simple_ps_bytecode), nullptr, &m_pPsSimple));

	// Initialize the input layout, and validate it against all the vertex shaders

	D3D11_INPUT_ELEMENT_DESC aInputDescs[] =
	{
		{ "POSITION", 0, DXGI_FORMAT_R32G32B32_FLOAT, 0, UINT(offsetof(Vertex, m_pos)), D3D11_INPUT_PER_VERTEX_DATA, 0 },
		{ "NORMAL", 0, DXGI_FORMAT_R32G32B32_FLOAT, 0, UINT(offsetof(Vertex, m_normal)), D3D11_INPUT_PER_VERTEX_DATA, 0 },
		{ "UV", 0, DXGI_FORMAT_R32G32_FLOAT, 0, UINT(offsetof(Vertex, m_uv)), D3D11_INPUT_PER_VERTEX_DATA, 0 },
	};
	CHECK_D3D(m_pDevice->CreateInputLayout(
							aInputDescs, dim(aInputDescs),
							world_vs_bytecode, dim(world_vs_bytecode),
							&m_pInputLayout));

	// Init constant buffers
	m_cbFrame.Init(m_pDevice);
	m_cbDebug.Init(m_pDevice);

	// Init the camera
	m_camera.m_moveSpeed = 3.0f;
	m_camera.m_mbuttonActivate = MBUTTON_Left;
	m_camera.m_pos = makepoint3(-8.7f, 6.8f, 0.0f);

#define ANT_TWEAK_BAR 0
#if ANT_TWEAK_BAR
	// Init AntTweakBar
	CHECK_ERR(TwInit(TW_DIRECT3D11, m_pDevice));

	// Automatically use the biggest font size
	TwDefine("GLOBAL fontsize=3 fontresizable=false");

	// Create bar for FPS display
	TwBar * pTwBarFPS = TwNewBar("FPS");
	TwDefine("FPS position='15 15' size='225 80' valueswidth=75 refresh=0.5");
	TwAddVarCB(
			pTwBarFPS, "Frame time (ms)", TW_TYPE_FLOAT,
			nullptr,
			[](void * value, void * timestep) { 
				*(float *)value = 1000.0f * *(float *)timestep;
			},
			&m_timer.m_timestep,
			"precision=2");
	TwAddVarCB(
			pTwBarFPS, "FPS", TW_TYPE_FLOAT,
			nullptr,
			[](void * value, void * timestep) { 
				*(float *)value = 1.0f / *(float *)timestep;
			},
			&m_timer.m_timestep,
			"precision=1");

	// Create bar for debug sliders
	TwBar * pTwBarDebug = TwNewBar("Debug");
	TwDefine("Debug position='15 110' size='225 115' valueswidth=75");
	TwAddVarRW(pTwBarDebug, "g_debugSlider0", TW_TYPE_FLOAT, &g_debugSlider0, "min=0.0 step=0.01 precision=2");
	TwAddVarRW(pTwBarDebug, "g_debugSlider1", TW_TYPE_FLOAT, &g_debugSlider1, "min=0.0 step=0.01 precision=2");
	TwAddVarRW(pTwBarDebug, "g_debugSlider2", TW_TYPE_FLOAT, &g_debugSlider2, "min=0.0 step=0.01 precision=2");
	TwAddVarRW(pTwBarDebug, "g_debugSlider3", TW_TYPE_FLOAT, &g_debugSlider3, "min=0.0 step=0.01 precision=2");

	// Create bar for lighting
	TwBar * pTwBarLight = TwNewBar("Lighting");
	TwDefine("Lighting position='15 240' size='275 355' valueswidth=130");
	TwAddVarRW(pTwBarLight, "Light direction", TW_TYPE_DIR3F, &g_vecDirectionalLight, nullptr);
	TwAddVarRW(pTwBarLight, "Light color", TW_TYPE_COLOR3F, &g_rgbDirectionalLight, nullptr);
	TwAddVarRW(pTwBarLight, "Sky color", TW_TYPE_COLOR3F, &g_srgbSky, nullptr);

	// Create bar for camera position and orientation
	TwBar * pTwBarCamera = TwNewBar("Camera");
	TwDefine("Camera position='255 15' size='195 180' valueswidth=75 refresh=0.5");
	TwAddVarRO(pTwBarCamera, "Camera X", TW_TYPE_FLOAT, &m_camera.m_pos.x, "precision=3");
	TwAddVarRO(pTwBarCamera, "Camera Y", TW_TYPE_FLOAT, &m_camera.m_pos.y, "precision=3");
	TwAddVarRO(pTwBarCamera, "Camera Z", TW_TYPE_FLOAT, &m_camera.m_pos.z, "precision=3");
	TwAddVarRO(pTwBarCamera, "Yaw", TW_TYPE_FLOAT, &m_camera.m_yaw, "precision=3");
	TwAddVarRO(pTwBarCamera, "Pitch", TW_TYPE_FLOAT, &m_camera.m_pitch, "precision=3");
	auto lambdaNegate = [](void * outValue, void * inValue) { *(float *)outValue = -*(float *)inValue; };
	TwAddVarCB(pTwBarCamera, "Look X", TW_TYPE_FLOAT, nullptr, lambdaNegate, &m_camera.m_viewToWorld.m_linear[2].x, "precision=3");
	TwAddVarCB(pTwBarCamera, "Look Y", TW_TYPE_FLOAT, nullptr, lambdaNegate, &m_camera.m_viewToWorld.m_linear[2].y, "precision=3");
	TwAddVarCB(pTwBarCamera, "Look Z", TW_TYPE_FLOAT, nullptr, lambdaNegate, &m_camera.m_viewToWorld.m_linear[2].z, "precision=3");
#endif // ANT_TWEAK_BAR

	// Take initial HMD pose as centered
	ovrHmd_RecenterPose(m_hmd);

	return true;
}

void TestWindow::Shutdown()
{
#if ANT_TWEAK_BAR
	TwTerminate();
#endif

	// Shutdown OVR stuff
	if (m_hmd)
	{
		ovrHmd_Destroy(m_hmd);
		m_hmd = nullptr;
	}
	ovr_Shutdown();

	super::Shutdown();
}

LRESULT TestWindow::MsgProc(HWND hWnd, UINT message, WPARAM wParam, LPARAM lParam)
{
	// Give AntTweakBar and the camera a crack at the message
#if ANT_TWEAK_BAR
	if (TwEventWin(hWnd, message, wParam, lParam))
		return 0;
#endif
	if (m_camera.HandleWindowsMessage(message, wParam, lParam))
		return 0;

	switch (message)
	{
	case WM_KEYDOWN:
		switch (wParam)
		{
		case VK_ESCAPE:
			Shutdown();
			break;

		case 'R':
			ovrHmd_RecenterPose(m_hmd);
			break;
		}
		return 0;

	default:
		return super::MsgProc(hWnd, message, wParam, lParam);
	}
}

void TestWindow::OnResize(int2_arg dimsNew)
{
	// Do nothing!
	(void) dimsNew;
}

void TestWindow::OnRender()
{
	m_timer.OnFrameStart();
	m_camera.Update(m_timer.m_timestep);

	// Hackily force camera pitch to zero, so pitch is only from HMD orientation
	m_camera.m_pitch = 0.0f;
	m_camera.UpdateOrientation();

	// Dismiss health & safety warning as soon as possible
	ovrHmd_DismissHSWDisplay(m_hmd);

	// Predict timings at which rendered frame will be displayed
	ovrFrameTiming timing = ovrHmd_BeginFrame(m_hmd, m_timer.m_frameCount);
	(void) timing;

	// Init D3D state
	m_pCtx->ClearState();
	m_pCtx->IASetInputLayout(m_pInputLayout);
	m_pCtx->RSSetState(m_pRsDefault);
	m_pCtx->OMSetDepthStencilState(m_pDssDepthTest, 0);

	// Set up whole-frame constant buffers (except for eye-specific stuff)

	CBFrame cbFrame =
	{
		float4x4::identity(),
		float4x4::identity(),
		{},
		0,
		g_vecDirectionalLight,
		0,
		g_rgbDirectionalLight,
		1.0f,
	};
	m_cbFrame.Bind(m_pCtx, CB_FRAME);

	CBDebug cbDebug =
	{
		// !!!UNDONE: move keyboard tracking into an input system that respects focus, etc.
		GetAsyncKeyState(' ') ? 1.0f : 0.0f,
		g_debugSlider0,
		g_debugSlider1,
		g_debugSlider2,
		g_debugSlider3,
	};
	m_cbDebug.Update(m_pCtx, &cbDebug);
	m_cbDebug.Bind(m_pCtx, CB_DEBUG);

	// Init render targets
	m_pCtx->ClearRenderTargetView(m_rtEyes.m_pRtv, makergba(toLinear(g_srgbSky), 1.0f));
	m_pCtx->ClearDepthStencilView(m_dstEyes.m_pDsv, D3D11_CLEAR_DEPTH, 1.0f, 0);
	BindRenderTargets(m_pCtx, &m_rtEyes, &m_dstEyes);

	// Init shaders
	m_pCtx->VSSetShader(m_pVsWorld, nullptr, 0);
	m_pCtx->PSSetShader(m_pPsSimple, nullptr, 0);
	m_pCtx->PSSetShaderResources(0, 1, &m_texStone.m_pSrv);
	m_pCtx->PSSetSamplers(0, 1, &m_pSsTrilinearRepeatAniso);

	// Render each eye, in the order that's best for the HMD scan order
	ovrPosef renderedEyePoses[2] = {};
	for (int i = 0; i < 2; ++i)
	{
		ovrEyeType currentEye = m_hmd->EyeRenderOrder[i];

		// Retrieve pose for the eye (predicted head-tracking state at
		// predicted time at which this eye will be scanned out)
		ovrPosef eyePose = ovrHmd_GetEyePose(m_hmd, currentEye);
		renderedEyePoses[currentEye] = eyePose;

		// Calculate new camera matrices incorporating the head-tracking pose and eye offsets
		// !!!UNDONE: support this in the camera classes
		float3 hmdOffset = makefloat3(
								eyePose.Position.x,
								eyePose.Position.y,
								eyePose.Position.z);
		quat hmdOrientation = makequat(
								eyePose.Orientation.w,
								eyePose.Orientation.x,
								eyePose.Orientation.y,
								eyePose.Orientation.z);
		affine3 hmdToCamera = makeaffine3(hmdOrientation, hmdOffset);
		affine3 eyeToWorld = translation(m_eyeOffsets[currentEye]) * hmdToCamera * m_camera.m_viewToWorld;
		affine3 worldToEye = transpose(eyeToWorld);
		float4x4 worldToClip = affineToHomogeneous(worldToEye) * m_eyeProjections[currentEye];

		// Update constant buffer data for the new matrices
		cbFrame.m_matWorldToClip = worldToClip;
		cbFrame.m_posCamera = makepoint3(eyeToWorld.m_translation);
		m_cbFrame.Update(m_pCtx, &cbFrame);

		// Set the viewport
		ibox2 viewport = m_eyeViewports[currentEye];
		D3D11_VIEWPORT d3dViewport =
		{
			float(viewport.m_mins.x), float(viewport.m_mins.y),
			float(viewport.diagonal().x), float(viewport.diagonal().y),
			0.0f, 1.0f,
		};
		m_pCtx->RSSetViewports(1, &d3dViewport);

		// Draw the world
		m_meshSponza.Draw(m_pCtx);
	}

#if ANT_TWEAK_BAR
	CHECK_WARN(TwDraw());
#endif

	ovrHmd_EndFrame(m_hmd, renderedEyePoses, &m_ovrEyeTextures[0].Texture);
}



// Get the whole shebang going

int WINAPI WinMain(HINSTANCE hInstance, HINSTANCE hPrevInstance, LPSTR lpCmdLine, int nCmdShow)
{
	(void)hPrevInstance;
	(void)lpCmdLine;
	(void)nCmdShow;

	TestWindow w;
	if (!w.Init(hInstance))
	{
		w.Shutdown();
		return 1;
	}

	w.MainLoop(SW_SHOWMAXIMIZED);
	return 0;
}
